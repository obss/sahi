{
  "$schema": "https://context7.com/schema/context7.json",
  "projectTitle": "SAHI - Slicing Aided Hyper Inference",
  "description": "A unified vision library providing a common API for multiple object detection and instance segmentation frameworks, supporting latest models like YOLO11/YOLO12, Roboflow Universe RF-DETR, HuggingFace DFine, with sliced inference, comprehensive COCO utilities, FiftyOne integration, error analysis, and advanced visualization tools",
  "folders": [
    "README.md",
    "CONTRIBUTING.md",
    "docs/**",
    "sahi/models/**",
    "sahi/utils/**",
    "sahi/scripts/**",
    "sahi/postprocess/**",
    "sahi/*.py"
  ],
  "excludeFolders": [
    "tests/**",
    "build/**", 
    "dist/**",
    "**/__pycache__",
    ".git/**",
    ".github/**",
    "**/*.egg-info",
    "demo/**"
  ],
  "excludeFiles": [
    "**/*.pyc",
    "**/*.pyo", 
    "**/*.pyd",
    "**/.DS_Store",
    "**/*.so",
    "**/*.dylib",
    "**/*.dll",
    "**/*.log",
    "**/*.pkl",
    "**/*.pickle",
    "**/*.pt",
    "**/*.pth",
    "**/*.onnx",
    "**/*.h5",
    "**/*.hdf5",
    "**/*.tar*",
    "**/*.gz",
    "**/*.zip",
    "setup.py",
    "pyproject.toml",
    "MANIFEST.in",
    "requirements*.txt",
    "**/*.ipynb"
  ],
  "rules": [
    "Use AutoDetectionModel.from_pretrained() to load any model - switch between Ultralytics/HuggingFace/Roboflow/MMDetection models by only changing model_type and model_path",
    "SAHI provides unified API across frameworks - same predict() function works with YOLO11/YOLO12, Roboflow Universe models, HuggingFace models like ustc-community/dfine-small-coco without code changes",
    "When using AutoDetectionModel.from_pretrained(): use 'model_path' parameter for file-based models (Ultralytics, HuggingFace), use 'model' parameter for Roboflow Universe models",
    "For academic papers requiring high mAP: use postprocess_type='NMS', postprocess_match_metric='IOU', and confidence_threshold=0.01",
    "For real-world applications: use postprocess_type='GREEDYNMM', postprocess_match_metric='IOS' for better performance with fewer false positives",
    "If getting many false positives in sliced inference, increase slice_height and slice_width values",
    "If getting multiple predictions on same object, decrease overlap_height_ratio and overlap_width_ratio (try 0.1 instead of 0.2)",
    "Use no_sliced_prediction=True to disable slicing and only perform standard inference (useful for large objects)",
    "Use no_standard_prediction=True to disable full-image inference and only use sliced predictions (saves computation when all objects are small)",
    "Cannot set both no_standard_prediction=True and no_sliced_prediction=True simultaneously",
    "Auto-slice resolution: if slice_height/slice_width not specified, SAHI automatically calculates optimal values based on image size",
    "For drone/satellite imagery: typically use slice_size=512-1024 with 0.2-0.3 overlap ratio",
    "SAHI is beneficial even without slicing - provides unified API, COCO utilities, visualization tools across all detection frameworks",
    "Use min_area_ratio parameter (default 0.1) to filter out partial objects at slice boundaries - lower values keep more edge objects",
    "For COCO datasets, always validate annotations with coco.stats before training or evaluation",
    "Export results in COCO format using dataset_json_path parameter for standardized evaluation",
    "Use visual_bbox_thickness, visual_text_size parameters to customize prediction visualizations",
    "Use 'sahi predict-fiftyone' command to visualize predictions interactively and sort by false positives",
    "Use 'sahi coco fiftyone' to compare multiple model predictions side-by-side in FiftyOne app",
    "Use 'sahi coco evaluate' for comprehensive COCO metrics with classwise AP/AR and custom IoU thresholds",
    "Use 'sahi coco analyse' to generate error analysis plots showing C75/C50/Localization/Similar/Other/Background/FalseNegative errors",
    "For error analysis: plots show performance breakdown by object size (small/medium/large) and error types",
    "Export predictions as cropped images using export_crop=True for dataset creation or further analysis",
    "For video inference: use frame_skip_interval to speed up processing, view_video=True for real-time display",
    "Supports latest models: YOLO11/YOLO12 via model_type='ultralytics', Roboflow Universe models (e.g., RF-DETR) via model_type='roboflow', HuggingFace models like 'ustc-community/dfine-small-coco' via model_type='huggingface'",
    "For YOLO11/YOLO12 OBB (oriented bounding box) models, SAHI automatically handles rotated box predictions and only supports NMS postprocessing",
    "Example model loading: model_type='ultralytics' with model_path='yolo11n.pt', model_type='huggingface' with model_path='ustc-community/dfine-small-coco', model_type='roboflow' with model='rfdetr-base'",
    "Roboflow Universe models: use simple string IDs like 'rfdetr-base' with model_type='roboflow' for easy access to pre-trained models",
    "Complete example: model = AutoDetectionModel.from_pretrained(model_type='roboflow', model='rfdetr-base', confidence_threshold=0.5)",
    "All models follow same API pattern: AutoDetectionModel.from_pretrained() → get_prediction() or get_sliced_prediction() → visualize results",
    "For models without built-in category mappings, provide category_mapping parameter (e.g., COCO_CLASSES from rfdetr.util.coco_classes)",
    "COCO utilities: merge datasets with coco.merge(), split train/val with split_coco_as_train_val(), filter by categories with update_categories()",
    "Filter COCO annotations by area using get_area_filtered_coco() - useful for focusing on specific object sizes",
    "Convert between formats: export_as_yolo() for YOLO format, use 'sahi coco yolo' command for batch conversion",
    "Use Coco.stats to get comprehensive dataset statistics before training (num annotations, area distribution, etc.)"
  ],
  "previousVersions": []
}
