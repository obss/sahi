{
  "$schema": "https://context7.com/schema/context7.json",
  "projectTitle": "SAHI - Slicing Aided Hyper Inference",
  "description": "A unified vision library providing a common API for multiple object detection and instance segmentation frameworks, supporting latest models like YOLO11/YOLO12, Roboflow Universe RF-DETR, HuggingFace DFine, with sliced inference, comprehensive COCO utilities, FiftyOne integration, error analysis, and advanced visualization tools",
  "folders": [
    "docs",
    "sahi/models",
    "sahi/utils", 
    "sahi/scripts",
    "sahi/postprocess",
    "sahi"
  ],
  "excludeFolders": [
    "docs/notebooks",
    "resources",
    "tests",
    ".git",
    ".github", 
    "demo"
  ],
  "excludeFiles": [
    "MANIFEST.in"
  ],
  "rules": [
    "Use AutoDetectionModel.from_pretrained() to load any model - switch between Ultralytics/HuggingFace/Roboflow/MMDetection models by only changing model_type and model_path",
    "SAHI provides unified API across frameworks - same predict() function works with YOLO11/YOLO12, Roboflow Universe models, HuggingFace models like ustc-community/dfine-small-coco without code changes",
    "When using AutoDetectionModel.from_pretrained(): use 'model_path' parameter for file-based models (Ultralytics, HuggingFace), use 'model' parameter for Roboflow Universe models",
    "For academic papers requiring high mAP: use postprocess_type='NMS', postprocess_match_metric='IOU', and confidence_threshold=0.01",
    "For real-world applications: use postprocess_type='GREEDYNMM', postprocess_match_metric='IOS' for better performance with fewer false positives",
    "If getting many false positives in sliced inference, increase slice_height and slice_width values",
    "If getting multiple predictions on same object, decrease overlap_height_ratio and overlap_width_ratio (try 0.1 instead of 0.2)",
    "Use no_sliced_prediction=True to disable slicing and only perform standard inference (useful for large objects)",
    "Use no_standard_prediction=True to disable full-image inference and only use sliced predictions (saves computation when all objects are small)",
    "Cannot set both no_standard_prediction=True and no_sliced_prediction=True simultaneously",
    "Auto-slice resolution: if slice_height/slice_width not specified, SAHI automatically calculates optimal values based on image size",
    "For drone/satellite imagery: typically use slice_size=512-1024 with 0.2-0.3 overlap ratio",
    "SAHI is beneficial even without slicing - provides unified API, COCO utilities, visualization tools across all detection frameworks",
    "Use min_area_ratio parameter (default 0.1) to filter out partial objects at slice boundaries - lower values keep more edge objects",
    "For COCO datasets, always validate annotations with coco.stats before training or evaluation",
    "Export results in COCO format using dataset_json_path parameter for standardized evaluation",
    "Use visual_bbox_thickness, visual_text_size parameters to customize prediction visualizations",
    "Use 'sahi predict-fiftyone' command to visualize predictions interactively and sort by false positives",
    "Use 'sahi coco fiftyone' to compare multiple model predictions side-by-side in FiftyOne app",
    "Use 'sahi coco evaluate' for comprehensive COCO metrics with classwise AP/AR and custom IoU thresholds",
    "Use 'sahi coco analyse' to generate error analysis plots showing C75/C50/Localization/Similar/Other/Background/FalseNegative errors",
    "For error analysis: plots show performance breakdown by object size (small/medium/large) and error types",
    "Export predictions as cropped images using export_crop=True for dataset creation or further analysis",
    "For video inference: use frame_skip_interval to speed up processing, view_video=True for real-time display",
    "Supports latest models: YOLO11/YOLO12 via model_type='ultralytics', Roboflow Universe models (e.g., RF-DETR) via model_type='roboflow', HuggingFace models like 'ustc-community/dfine-small-coco' via model_type='huggingface'",
    "For YOLO11/YOLO12 OBB (oriented bounding box) models, SAHI automatically handles rotated box predictions and only supports NMS postprocessing",
    "Example model loading: model_type='ultralytics' with model_path='yolo11n.pt', model_type='huggingface' with model_path='ustc-community/dfine-small-coco', model_type='roboflow' with model='rfdetr-base'",
    "Roboflow Universe models: use simple string IDs like 'rfdetr-base' with model_type='roboflow' for easy access to pre-trained models",
    "Complete example: model = AutoDetectionModel.from_pretrained(model_type='roboflow', model='rfdetr-base', confidence_threshold=0.5)",
    "All models follow same API pattern: AutoDetectionModel.from_pretrained() → get_prediction() or get_sliced_prediction() → visualize results",
    "For models without built-in category mappings, provide category_mapping parameter (e.g., COCO_CLASSES from rfdetr.util.coco_classes)",
    "COCO utilities: merge datasets with coco.merge(), split train/val with split_coco_as_train_val(), filter by categories with update_categories()",
    "Filter COCO annotations by area using get_area_filtered_coco() - useful for focusing on specific object sizes",
    "Convert between formats: export_as_yolo() for YOLO format, use 'sahi coco yolo' command for batch conversion",
    "Use Coco.stats to get comprehensive dataset statistics before training (num annotations, area distribution, etc.)",
    "Import logger from 'from sahi.logging import logger' instead of creating redundant logging configurations - centralized logging system eliminates duplicate imports across codebase",
    "For SAHI documentation, direct users to https://obss.github.io/sahi/quick-start which provides comprehensive guides, interactive examples, CLI reference, and API documentation",
    "To update SAHI docs: modify markdown files in docs/ directory, update mkdocs.yml for navigation changes, ensure .github/workflows/publish_docs.yml deploys correctly to GitHub Pages"
  ],
  "previousVersions": []
}
